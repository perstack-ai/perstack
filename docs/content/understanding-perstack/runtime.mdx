import { Callout } from 'nextra/components'

# Runtime

The Perstack runtime combines probabilistic LLM reasoning with deterministic state management — making agent execution predictable, reproducible, and auditable.

## Execution model

The runtime organizes execution into a three-level hierarchy:

```
Job (jobId)
 ├── Run 1 (runId, Coordinator Expert)
 │    └── Checkpoints...
 ├── Run 2 (runId, Delegated Expert A)
 │    └── Checkpoints...
 └── Run 3 (runId, Delegated Expert B)
      └── Checkpoints...
```

| Concept | Description |
|---------|-------------|
| **Job** | Top-level execution unit. Created per `perstack run` invocation. Contains all Runs. |
| **Run** | Single Expert execution. Each delegation creates a new Run within the same Job. |
| **Checkpoint** | Snapshot at the end of each step within a Run. |

### Coordinator vs. Delegated Expert

| Role | Description |
|------|-------------|
| **Coordinator Expert** | The initial Expert that starts a Job. Has full capabilities. |
| **Delegated Expert** | Expert started via delegation. Restricted capabilities. |

Key differences:

| Capability | Coordinator | Delegated |
|------------|-------------|-----------|
| Interactive tool calls | ✅ Available | ❌ Not available |
| `--continue` / `--resume-from` | ✅ Supported | ❌ Not supported |
| Context from parent | N/A | Only the query (no shared history) |

<Callout type="info">
Delegated Experts cannot use interactive tools. See [Why no interactive tools for delegates?](/understanding-perstack/experts#why-no-interactive-tools-for-delegates)
</Callout>

## Agent loop

Each Run executes through an agent loop:

```
┌─────────────────────────────────────────────────────┐
│  1. Reason    →  LLM decides next action            │
│  2. Act       →  Runtime executes tool              │
│  3. Record    →  Checkpoint saved                   │
│  4. Repeat    →  Until completion or limit          │
└─────────────────────────────────────────────────────┘
```

The loop ends when:
- LLM calls `attemptCompletion` with all todos complete (or no todos)
- Job reaches `maxSteps` limit
- External signal (SIGTERM/SIGINT)

When `attemptCompletion` is called, the runtime checks the todo list. If incomplete todos remain, they are returned to the LLM to continue work. This prevents premature completion and ensures all planned tasks are addressed.

### Step counting

Each Run maintains its own `stepNumber`, starting from 1. The Job tracks total steps across all Runs:

```
Job (totalSteps = 8)
 ├── Run 1: stepNumber 1 → 2 → 3          (3 steps)
 ├── Run 2: stepNumber 1 → 2              (2 steps)
 └── Run 3: stepNumber 1 → 2 → 3          (3 steps)
```

The `maxSteps` limit applies to the Job's total steps, not individual Runs.

### Stopping and resuming

```bash
npx perstack run my-expert "query" --max-steps 50
```

| Stop condition | Behavior | Resume from |
|----------------|----------|-------------|
| `attemptCompletion` (no remaining todos) | Task complete | N/A |
| `attemptCompletion` (remaining todos) | Continue loop | N/A (loop continues) |
| `maxSteps` reached | Graceful stop | Coordinator's last checkpoint |
| SIGTERM/SIGINT | Immediate stop | Coordinator's previous checkpoint |

<Callout type="warning">
`--continue` and `--resume-from` only work with the Coordinator Expert's checkpoints. You cannot resume from a Delegated Expert's checkpoint.
</Callout>

## Deterministic state

LLMs are probabilistic — same input can produce different outputs. Perstack draws a clear boundary:

| Probabilistic (LLM) | Deterministic (Runtime) |
|---------------------|-------------------------|
| Which tool to call | Tool execution |
| Todo management decisions | State recording |
| Reasoning | Checkpoint creation |

The "thinking" is probabilistic; the "doing" and "recording" are deterministic. This boundary enables:
- **Reproducibility**: Replay from any checkpoint with identical state
- **Testability**: Mock the LLM, test the runtime deterministically

### Event, Step, Checkpoint

Runtime state is built on three concepts:

| Concept | What it represents |
|---------|-------------------|
| **Event** | A single state transition (tool call, result, etc.) |
| **Step** | One cycle of the agent loop |
| **Checkpoint** | Complete snapshot at step end — everything needed to resume |

This combines **Event Sourcing** (complete history) with **Checkpoint/Restore** (efficient resume).

### The `perstack/` directory

The runtime stores execution history in `perstack/jobs/` within the workspace:

```
/workspace
└── perstack/
    └── jobs/
        └── {jobId}/
            ├── job.json                                   # Job metadata
            └── runs/
                └── {runId}/
                    ├── run-setting.json                   # Run configuration
                    ├── checkpoint-{timestamp}-{step}-{id}.json
                    └── event-{timestamp}-{step}-{type}.json
```

This directory is managed automatically — don't modify it manually.

## Event notification

The runtime emits events for every state change. Two options:

### stdout (default)

Events are written to stdout as JSON. This is the safest option for sandboxed environments — no network access required.

```bash
npx perstack run my-expert "query"
```

Your infrastructure reads stdout and decides what to do with events. See [Sandbox Integration](/understanding-perstack/sandbox-integration) for the rationale.

### Custom event listener

When embedding the runtime programmatically, use a callback:

```typescript
import { run } from "@perstack/runtime"

await run(params, {
  eventListener: (event) => {
    // Send to your monitoring system, database, etc.
  }
})
```

## Skills (MCP)

Experts use tools through MCP (Model Context Protocol). The runtime handles:

- **Lifecycle**: Start MCP servers with Expert, clean up on exit
- **Environment isolation**: Only `requiredEnv` variables are passed
- **Error recovery**: MCP failures are fed back to LLM, not thrown as runtime errors

For skill configuration, see [Skills](/making-experts/skills).

## Providers and models

Perstack uses standard LLM features available from most providers:
- Chat completion (including PDF/image in messages)
- Tool calling

For supported providers and models, see [Providers and Models](/references/providers-and-models).
