## Description

Enhance DeepSeek provider with error handling, reasoning support, and cache token usage tracking.

Related to #225, #190, #191, #192

### Use Case

Improve DeepSeek provider with:
- Proper error normalization for DeepSeek-specific errors
- Retry logic for DeepSeek rate limits
- Reasoning support for the deepseek-reasoner model
- Cache token usage metadata access

### Current State

The @perstack/deepseek-provider package has minimal implementation:
- Only createModel() is implemented
- No normalizeError() / isRetryable() implementations
- No reasoning configuration support

### Target State

Enhanced provider adapter implementation:
1. **errors.ts**: Normalize DeepSeek errors and determine retry eligibility
2. **adapter.ts**: Wire up error handling and expose metadata

### Implementation Notes

**No Provider Tools**: DeepSeek does not provide provider-defined tools like Anthropic/OpenAI/Google. The getProviderTools() method will return an empty object (default behavior).

**Reasoning Model**: The deepseek-reasoner model streams reasoning tokens that are exposed as reasoning stream parts. The AI SDK handles this automatically, but:
- Consider documenting how to enable/use reasoning
- Ensure error handling does not interfere with reasoning streams

**Cache Token Usage**: DeepSeek provides disk-based context caching with metrics:
- promptCacheHitTokens: Tokens that hit cache
- promptCacheMissTokens: Tokens that missed cache
These are returned in providerMetadata.deepseek - consider exposing this in runtime.

Refer to: https://ai-sdk.dev/providers/ai-sdk-providers/deepseek

### Proposed Solution

1. Create errors.ts with DeepSeek-specific error handling:
   - Handle API errors (authentication, validation, rate limits)
   - Implement retry logic for rate limits and overload

2. Update adapter.ts:
   - Override normalizeError() and isRetryable()
   - Document that getProviderTools() returns empty (no tools available)

3. Document reasoning usage in expert configuration

### Configuration Example

```toml
[provider]
providerName = "deepseek"

[provider.config]
apiKey = "$DEEPSEEK_API_KEY"

# For reasoning tasks
[experts.reasoning-assistant]
modelId = "deepseek-reasoner"

# For general chat
[experts.chat-assistant]
modelId = "deepseek-chat"
```

### Acceptance Criteria

- [ ] Error normalization follows DeepSeek error format
- [ ] Retry logic handles DeepSeek-specific rate limits
- [ ] Reasoning works correctly with deepseek-reasoner model
- [ ] Cache token usage metadata is accessible
- [ ] Documentation clarifies no provider tools are available
- [ ] Unit tests added
- [ ] E2E test added (if API access available)
